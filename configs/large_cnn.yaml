train:
  # Batch size
  batchsize: 512
  # Learning rate
  lr: 0.001
  # Exponential decay gamma. Lower values reduce lr faster.
  exponential_decay: 0.999
  # L2 Regularization lambda value.
  reg_l2: 0.0005
  # Beta value for SGD with momentum.
  momentum: 0.9
  model: LargeCNN # e.g.: Linear, SmallCNN, etc.
  model_blocks: 14
  model_num_filters: 64
