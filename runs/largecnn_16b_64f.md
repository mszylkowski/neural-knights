# Training `largecnn_16b_64f`

Started on `2024-04-23 11:53:14.170542`

**Description:** Add description here

Arguments:
- **`--name`**: largecnn_16b_64f
- **`--test`**: False
- **`--config`**: <_io.TextIOWrapper name='.\\configs\\large_cnn.yaml' mode='r' encoding='cp1252'>
- **`--batchsize`**: 512
- **`--lr`**: 0.001
- **`--exponential_decay`**: 0.999
- **`--reg_l2`**: 0.0005
- **`--momentum`**: 0.9
- **`--model`**: LargeCNN
- **`--model_blocks`**: 16
- **`--model_num_filters`**: 64
- **`--criterion`**: CrossEntropyLoss()
- **`--optimizer`**: SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0005
)

## Model

Saved in `runs/largecnn_16b_64f.pt`

```
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
LargeCNN                                 [512, 1796]               --
├─Conv2d: 1-1                            [512, 64, 8, 8]           6,976
├─ELU: 1-2                               [512, 64, 8, 8]           --
├─Sequential: 1-3                        [512, 64, 8, 8]           --
│    └─Conv2d: 2-1                       [512, 64, 8, 8]           36,928
│    └─ELU: 2-2                          [512, 64, 8, 8]           --
│    └─Conv2d: 2-3                       [512, 64, 8, 8]           36,928
│    └─ELU: 2-4                          [512, 64, 8, 8]           --
│    └─Conv2d: 2-5                       [512, 64, 8, 8]           36,928
│    └─ELU: 2-6                          [512, 64, 8, 8]           --
│    └─Conv2d: 2-7                       [512, 64, 8, 8]           36,928
│    └─ELU: 2-8                          [512, 64, 8, 8]           --
│    └─Conv2d: 2-9                       [512, 64, 8, 8]           36,928
│    └─ELU: 2-10                         [512, 64, 8, 8]           --
│    └─Conv2d: 2-11                      [512, 64, 8, 8]           36,928
│    └─ELU: 2-12                         [512, 64, 8, 8]           --
│    └─Conv2d: 2-13                      [512, 64, 8, 8]           36,928
│    └─ELU: 2-14                         [512, 64, 8, 8]           --
│    └─Conv2d: 2-15                      [512, 64, 8, 8]           36,928
│    └─ELU: 2-16                         [512, 64, 8, 8]           --
│    └─Conv2d: 2-17                      [512, 64, 8, 8]           36,928
│    └─ELU: 2-18                         [512, 64, 8, 8]           --
│    └─Conv2d: 2-19                      [512, 64, 8, 8]           36,928
│    └─ELU: 2-20                         [512, 64, 8, 8]           --
│    └─Conv2d: 2-21                      [512, 64, 8, 8]           36,928
│    └─ELU: 2-22                         [512, 64, 8, 8]           --
│    └─Conv2d: 2-23                      [512, 64, 8, 8]           36,928
│    └─ELU: 2-24                         [512, 64, 8, 8]           --
│    └─Conv2d: 2-25                      [512, 64, 8, 8]           36,928
│    └─ELU: 2-26                         [512, 64, 8, 8]           --
│    └─Conv2d: 2-27                      [512, 64, 8, 8]           36,928
│    └─ELU: 2-28                         [512, 64, 8, 8]           --
│    └─Conv2d: 2-29                      [512, 64, 8, 8]           36,928
│    └─ELU: 2-30                         [512, 64, 8, 8]           --
├─Linear: 1-4                            [512, 1796]               7,358,212
==========================================================================================
Total params: 7,919,108
Trainable params: 7,919,108
Non-trainable params: 0
Total mult-adds (Units.GIGABYTES): 22.15
==========================================================================================
Input size (MB): 1.57
Forward/backward pass size (MB): 275.79
Params size (MB): 31.68
Estimated Total Size (MB): 309.04
==========================================================================================
```

## Training

| Epoch | Train/Val | Loss | Acc | Time |
| - | - | - | - | - |
| 00000 | training | 7.494 | 0.000 | ---------- |
| -------- | validation | 7.496 | 0.000 | 8 |
| 00010 | training | 6.650 | 0.022 | ---------- |
| -------- | validation | 6.228 | 0.025 | 42 |
| 00020 | training | 6.251 | 0.023 | ---------- |
| -------- | validation | 6.225 | 0.024 | 75 |
| 00030 | training | 6.244 | 0.023 | ---------- |
| -------- | validation | 6.206 | 0.026 | 108 |
| 00040 | training | 6.245 | 0.023 | ---------- |
| -------- | validation | 6.196 | 0.029 | 142 |
| 00050 | training | 6.238 | 0.024 | ---------- |
| -------- | validation | 6.246 | 0.023 | 175 |
| 00060 | training | 6.234 | 0.024 | ---------- |
| -------- | validation | 6.213 | 0.027 | 208 |
| 00070 | training | 6.239 | 0.024 | ---------- |
| -------- | validation | 6.216 | 0.025 | 242 |
| 00080 | training | 6.238 | 0.024 | ---------- |
| -------- | validation | 6.197 | 0.025 | 275 |
| 00090 | training | 6.228 | 0.025 | ---------- |
| -------- | validation | 6.211 | 0.022 | 308 |
| 00100 | training | 6.236 | 0.024 | ---------- |
| -------- | validation | 6.211 | 0.028 | 341 |
| 00110 | training | 6.236 | 0.024 | ---------- |
| -------- | validation | 6.227 | 0.028 | 375 |
| 00120 | training | 6.228 | 0.024 | ---------- |
| -------- | validation | 6.245 | 0.023 | 408 |
| 00130 | training | 6.227 | 0.024 | ---------- |
| -------- | validation | 6.231 | 0.021 | 441 |
| 00140 | training | 6.231 | 0.025 | ---------- |
| -------- | validation | 6.201 | 0.029 | 474 |
| 00150 | training | 6.225 | 0.025 | ---------- |
| -------- | validation | 6.233 | 0.023 | 507 |
| 00160 | training | 6.224 | 0.025 | ---------- |
| -------- | validation | 6.200 | 0.025 | 540 |
| 00170 | training | 6.222 | 0.025 | ---------- |
| -------- | validation | 6.185 | 0.024 | 574 |
| 00180 | training | 6.222 | 0.025 | ---------- |
| -------- | validation | 6.255 | 0.022 | 607 |
| 00190 | training | 6.218 | 0.025 | ---------- |
| -------- | validation | 6.186 | 0.026 | 640 |
| 00200 | training | 6.224 | 0.025 | ---------- |
| -------- | validation | 6.214 | 0.026 | 673 |
| 00210 | training | 6.228 | 0.025 | ---------- |
| -------- | validation | 6.218 | 0.026 | 706 |
| 00220 | training | 6.227 | 0.025 | ---------- |
| -------- | validation | 6.215 | 0.028 | 739 |
| 00230 | training | 6.228 | 0.025 | ---------- |
| -------- | validation | 6.182 | 0.027 | 772 |
| 00240 | training | 6.230 | 0.025 | ---------- |
| -------- | validation | 6.187 | 0.026 | 805 |
| 00250 | training | 6.222 | 0.025 | ---------- |
| -------- | validation | 6.203 | 0.024 | 839 |
| 00260 | training | 6.226 | 0.024 | ---------- |
| -------- | validation | 6.247 | 0.023 | 872 |
| 00270 | training | 6.224 | 0.025 | ---------- |
| -------- | validation | 6.183 | 0.025 | 905 |
| 00280 | training | 6.212 | 0.025 | ---------- |
| -------- | validation | 6.204 | 0.024 | 938 |
| 00290 | training | 6.213 | 0.025 | ---------- |
| -------- | validation | 6.169 | 0.025 | 971 |
| 00300 | training | 6.223 | 0.024 | ---------- |
| -------- | validation | 6.200 | 0.021 | 1004 |
| 00310 | training | 6.224 | 0.025 | ---------- |
| -------- | validation | 6.202 | 0.028 | 1037 |
| 00320 | training | 6.215 | 0.025 | ---------- |
| -------- | validation | 6.194 | 0.026 | 1070 |
| 00330 | training | 6.218 | 0.024 | ---------- |
| -------- | validation | 6.216 | 0.027 | 1103 |
| 00340 | training | 6.220 | 0.025 | ---------- |
| -------- | validation | 6.247 | 0.026 | 1136 |
