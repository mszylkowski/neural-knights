# Training `linear_1024h_4l`

Started on `2024-04-24 16:52:46.109893`

**Description:** Add description here

Arguments:
- **`--name`**: linear_1024h_4l
- **`--test`**: False
- **`--config`**: <_io.TextIOWrapper name='.\\configs\\linear.yaml' mode='r' encoding='cp1252'>
- **`--batchsize`**: 512
- **`--lr`**: 0.01
- **`--exponential_decay`**: 0.9999
- **`--reg_l2`**: 0.0005
- **`--momentum`**: 0.9
- **`--model`**: Linear
- **`--model_hidden_layers`**: 4
- **`--model_hidden_size`**: 1024
- **`--criterion`**: CrossEntropyLoss()
- **`--optimizer`**: SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    initial_lr: 0.01
    lr: 0.01
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0005
)

## Model

Saved in `runs/linear_1024h_4l.pt`

```
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Linear                                   [512, 1796]               --
├─Linear: 1-1                            [512, 1024]               787,456
├─ELU: 1-2                               [512, 1024]               --
├─Sequential: 1-3                        [512, 1024]               --
│    └─Linear: 2-1                       [512, 1024]               1,049,600
│    └─ELU: 2-2                          [512, 1024]               --
│    └─Linear: 2-3                       [512, 1024]               1,049,600
│    └─ELU: 2-4                          [512, 1024]               --
│    └─Linear: 2-5                       [512, 1024]               1,049,600
│    └─ELU: 2-6                          [512, 1024]               --
├─Linear: 1-4                            [512, 1796]               1,840,900
==========================================================================================
Total params: 5,777,156
Trainable params: 5,777,156
Non-trainable params: 0
Total mult-adds (Units.GIGABYTES): 2.96
==========================================================================================
Input size (MB): 1.57
Forward/backward pass size (MB): 24.13
Params size (MB): 23.11
Estimated Total Size (MB): 48.82
==========================================================================================
```

## Training

| Epoch | Train/Val | Loss | Acc | Time |
| - | - | - | - | - |
| 00000 | training | 7.494 | 0.000 | ---------- |
| -------- | validation | 7.495 | 0.000 | 33 |
| 00010 | training | 6.125 | 0.036 | ---------- |
| -------- | validation | 5.822 | 0.054 | 59 |
| 00020 | training | 5.778 | 0.060 | ---------- |
| -------- | validation | 5.706 | 0.068 | 84 |
| 00030 | training | 5.572 | 0.081 | ---------- |
| -------- | validation | 5.495 | 0.085 | 110 |
| 00040 | training | 5.380 | 0.096 | ---------- |
| -------- | validation | 5.227 | 0.108 | 136 |
| 00050 | training | 5.182 | 0.109 | ---------- |
| -------- | validation | 5.123 | 0.124 | 162 |
| 00060 | training | 5.005 | 0.118 | ---------- |
| -------- | validation | 4.955 | 0.118 | 187 |
| 00070 | training | 4.840 | 0.127 | ---------- |
| -------- | validation | 4.720 | 0.131 | 213 |
| 00080 | training | 4.684 | 0.135 | ---------- |
| -------- | validation | 4.574 | 0.148 | 240 |
| 00090 | training | 4.528 | 0.144 | ---------- |
| -------- | validation | 4.465 | 0.149 | 266 |
| 00100 | training | 4.410 | 0.150 | ---------- |
| -------- | validation | 4.301 | 0.156 | 293 |
| 00110 | training | 4.299 | 0.155 | ---------- |
| -------- | validation | 4.229 | 0.157 | 320 |
| 00120 | training | 4.211 | 0.160 | ---------- |
| -------- | validation | 4.239 | 0.158 | 347 |
| 00130 | training | 4.144 | 0.162 | ---------- |
| -------- | validation | 4.084 | 0.161 | 372 |
| 00140 | training | 4.078 | 0.165 | ---------- |
| -------- | validation | 4.066 | 0.164 | 398 |
| 00150 | training | 4.013 | 0.168 | ---------- |
| -------- | validation | 3.968 | 0.165 | 423 |
| 00160 | training | 3.963 | 0.170 | ---------- |
| -------- | validation | 3.963 | 0.174 | 449 |
| 00170 | training | 3.914 | 0.172 | ---------- |
| -------- | validation | 3.869 | 0.170 | 476 |
| 00180 | training | 3.871 | 0.174 | ---------- |
| -------- | validation | 3.929 | 0.172 | 504 |
| 00190 | training | 3.838 | 0.176 | ---------- |
| -------- | validation | 3.796 | 0.179 | 530 |
| 00200 | training | 3.801 | 0.177 | ---------- |
| -------- | validation | 3.789 | 0.181 | 558 |
| 00210 | training | 3.773 | 0.178 | ---------- |
| -------- | validation | 3.798 | 0.176 | 584 |
| 00220 | training | 3.742 | 0.181 | ---------- |
| -------- | validation | 3.739 | 0.181 | 610 |
| 00230 | training | 3.725 | 0.181 | ---------- |
| -------- | validation | 3.695 | 0.182 | 636 |
| 00240 | training | 3.698 | 0.183 | ---------- |
| -------- | validation | 3.679 | 0.191 | 663 |
| 00250 | training | 3.671 | 0.185 | ---------- |
| -------- | validation | 3.566 | 0.196 | 690 |
| 00260 | training | 3.659 | 0.186 | ---------- |
| -------- | validation | 3.623 | 0.187 | 716 |
| 00270 | training | 3.638 | 0.185 | ---------- |
| -------- | validation | 3.658 | 0.186 | 742 |
| 00280 | training | 3.605 | 0.190 | ---------- |
| -------- | validation | 3.602 | 0.190 | 768 |
| 00290 | training | 3.587 | 0.192 | ---------- |
| -------- | validation | 3.574 | 0.191 | 795 |
| 00300 | training | 3.582 | 0.190 | ---------- |
| -------- | validation | 3.577 | 0.196 | 820 |
| 00310 | training | 3.572 | 0.192 | ---------- |
| -------- | validation | 3.521 | 0.193 | 846 |
| 00320 | training | 3.554 | 0.193 | ---------- |
| -------- | validation | 3.517 | 0.198 | 872 |
| 00330 | training | 3.541 | 0.194 | ---------- |
| -------- | validation | 3.539 | 0.198 | 898 |
| 00340 | training | 3.532 | 0.194 | ---------- |
| -------- | validation | 3.485 | 0.196 | 924 |
| 00350 | training | 3.514 | 0.196 | ---------- |
| -------- | validation | 3.480 | 0.189 | 950 |
| 00360 | training | 3.501 | 0.198 | ---------- |
| -------- | validation | 3.531 | 0.195 | 977 |
| 00370 | training | 3.491 | 0.198 | ---------- |
| -------- | validation | 3.491 | 0.197 | 1003 |
| 00380 | training | 3.492 | 0.197 | ---------- |
| -------- | validation | 3.494 | 0.201 | 1029 |
| 00390 | training | 3.482 | 0.199 | ---------- |
| -------- | validation | 3.472 | 0.200 | 1055 |
| 00400 | training | 3.481 | 0.198 | ---------- |
| -------- | validation | 3.443 | 0.207 | 1080 |
| 00410 | training | 3.462 | 0.200 | ---------- |
| -------- | validation | 3.445 | 0.202 | 1107 |
| 00420 | training | 3.458 | 0.202 | ---------- |
| -------- | validation | 3.359 | 0.223 | 1133 |
| 00430 | training | 3.454 | 0.200 | ---------- |
| -------- | validation | 3.443 | 0.203 | 1159 |
| 00440 | training | 3.443 | 0.201 | ---------- |
| -------- | validation | 3.463 | 0.198 | 1186 |
| 00450 | training | 3.435 | 0.202 | ---------- |
| -------- | validation | 3.425 | 0.201 | 1213 |
| 00460 | training | 3.430 | 0.203 | ---------- |
| -------- | validation | 3.373 | 0.206 | 1240 |
| 00470 | training | 3.422 | 0.203 | ---------- |
| -------- | validation | 3.350 | 0.213 | 1266 |
| 00480 | training | 3.424 | 0.203 | ---------- |
| -------- | validation | 3.432 | 0.206 | 1294 |
| 00490 | training | 3.419 | 0.204 | ---------- |
| -------- | validation | 3.378 | 0.210 | 1319 |
| 00500 | training | 3.412 | 0.203 | ---------- |
| -------- | validation | 3.392 | 0.203 | 1345 |
| 00510 | training | 3.397 | 0.206 | ---------- |
| -------- | validation | 3.398 | 0.211 | 1370 |
| 00520 | training | 3.390 | 0.205 | ---------- |
| -------- | validation | 3.419 | 0.210 | 1395 |
| 00530 | training | 3.388 | 0.206 | ---------- |
| -------- | validation | 3.359 | 0.214 | 1420 |
| 00540 | training | 3.390 | 0.206 | ---------- |
| -------- | validation | 3.357 | 0.215 | 1444 |
| 00550 | training | 3.386 | 0.207 | ---------- |
| -------- | validation | 3.325 | 0.215 | 1469 |
| 00560 | training | 3.380 | 0.207 | ---------- |
| -------- | validation | 3.327 | 0.210 | 1495 |
| 00570 | training | 3.377 | 0.207 | ---------- |
| -------- | validation | 3.376 | 0.216 | 1520 |
| 00580 | training | 3.357 | 0.209 | ---------- |
| -------- | validation | 3.352 | 0.213 | 1545 |
| 00590 | training | 3.355 | 0.209 | ---------- |
| -------- | validation | 3.363 | 0.213 | 1570 |
| 00600 | training | 3.355 | 0.209 | ---------- |
| -------- | validation | 3.323 | 0.220 | 1595 |
| 00610 | training | 3.350 | 0.209 | ---------- |
| -------- | validation | 3.390 | 0.209 | 1620 |
| 00620 | training | 3.347 | 0.210 | ---------- |
| -------- | validation | 3.345 | 0.211 | 1647 |
| 00630 | training | 3.345 | 0.210 | ---------- |
| -------- | validation | 3.349 | 0.209 | 1673 |
| 00640 | training | 3.336 | 0.211 | ---------- |
| -------- | validation | 3.330 | 0.213 | 1699 |
| 00650 | training | 3.335 | 0.210 | ---------- |
| -------- | validation | 3.307 | 0.209 | 1724 |
| 00660 | training | 3.329 | 0.213 | ---------- |
| -------- | validation | 3.314 | 0.213 | 1750 |
| 00670 | training | 3.328 | 0.211 | ---------- |
| -------- | validation | 3.378 | 0.200 | 1775 |
| 00680 | training | 3.332 | 0.212 | ---------- |
| -------- | validation | 3.293 | 0.211 | 1800 |
| 00690 | training | 3.325 | 0.212 | ---------- |
| -------- | validation | 3.338 | 0.216 | 1825 |
| 00700 | training | 3.311 | 0.214 | ---------- |
| -------- | validation | 3.311 | 0.215 | 1851 |
| 00710 | training | 3.318 | 0.212 | ---------- |
| -------- | validation | 3.325 | 0.212 | 1878 |
| 00720 | training | 3.316 | 0.213 | ---------- |
| -------- | validation | 3.250 | 0.221 | 1906 |
| 00730 | training | 3.312 | 0.213 | ---------- |
| -------- | validation | 3.303 | 0.218 | 1932 |
| 00740 | training | 3.304 | 0.213 | ---------- |
| -------- | validation | 3.333 | 0.205 | 1957 |
| 00750 | training | 3.308 | 0.213 | ---------- |
| -------- | validation | 3.304 | 0.214 | 1982 |
| 00760 | training | 3.304 | 0.214 | ---------- |
| -------- | validation | 3.314 | 0.204 | 2007 |
| 00770 | training | 3.303 | 0.213 | ---------- |
| -------- | validation | 3.254 | 0.220 | 2033 |
| 00780 | training | 3.305 | 0.213 | ---------- |
| -------- | validation | 3.309 | 0.207 | 2058 |
| 00790 | training | 3.289 | 0.215 | ---------- |
| -------- | validation | 3.286 | 0.220 | 2083 |
| 00800 | training | 3.294 | 0.215 | ---------- |
| -------- | validation | 3.290 | 0.202 | 2108 |
| 00810 | training | 3.290 | 0.215 | ---------- |
| -------- | validation | 3.285 | 0.218 | 2133 |
| 00820 | training | 3.294 | 0.214 | ---------- |
| -------- | validation | 3.318 | 0.204 | 2159 |
| 00830 | training | 3.293 | 0.215 | ---------- |
| -------- | validation | 3.283 | 0.209 | 2186 |
| 00840 | training | 3.287 | 0.216 | ---------- |
| -------- | validation | 3.331 | 0.208 | 2213 |
| 00850 | training | 3.279 | 0.215 | ---------- |
| -------- | validation | 3.297 | 0.214 | 2239 |
| 00860 | training | 3.283 | 0.215 | ---------- |
| -------- | validation | 3.246 | 0.217 | 2264 |
| 00870 | training | 3.275 | 0.216 | ---------- |
| -------- | validation | 3.291 | 0.217 | 2290 |
| 00880 | training | 3.274 | 0.216 | ---------- |
| -------- | validation | 3.255 | 0.223 | 2316 |
| 00890 | training | 3.276 | 0.217 | ---------- |
| -------- | validation | 3.237 | 0.225 | 2342 |
| 00900 | training | 3.282 | 0.214 | ---------- |
| -------- | validation | 3.230 | 0.219 | 2367 |
| 00910 | training | 3.280 | 0.215 | ---------- |
| -------- | validation | 3.240 | 0.222 | 2392 |
| 00920 | training | 3.267 | 0.217 | ---------- |
| -------- | validation | 3.242 | 0.225 | 2418 |
| 00930 | training | 3.272 | 0.215 | ---------- |
| -------- | validation | 3.314 | 0.213 | 2445 |
| 00940 | training | 3.264 | 0.216 | ---------- |
| -------- | validation | 3.232 | 0.222 | 2472 |
| 00950 | training | 3.268 | 0.215 | ---------- |
| -------- | validation | 3.291 | 0.217 | 2507 |
| 00960 | training | 3.261 | 0.218 | ---------- |
| -------- | validation | 3.246 | 0.216 | 2540 |
| 00970 | training | 3.268 | 0.215 | ---------- |
| -------- | validation | 3.299 | 0.219 | 2569 |
| 00980 | training | 3.258 | 0.218 | ---------- |
| -------- | validation | 3.243 | 0.219 | 2601 |
| 00990 | training | 3.254 | 0.218 | ---------- |
| -------- | validation | 3.255 | 0.217 | 2632 |
| 01000 | training | 3.259 | 0.217 | ---------- |
| -------- | validation | 3.273 | 0.221 | 2660 |
| 01010 | training | 3.262 | 0.217 | ---------- |
| -------- | validation | 3.251 | 0.213 | 2686 |
| 01020 | training | 3.255 | 0.217 | ---------- |
| -------- | validation | 3.341 | 0.206 | 2712 |
| 01030 | training | 3.247 | 0.218 | ---------- |
| -------- | validation | 3.238 | 0.218 | 2740 |
| 01040 | training | 3.245 | 0.219 | ---------- |
| -------- | validation | 3.261 | 0.210 | 2766 |
| 01050 | training | 3.245 | 0.218 | ---------- |
| -------- | validation | 3.230 | 0.225 | 2793 |
| 01060 | training | 3.241 | 0.219 | ---------- |
| -------- | validation | 3.205 | 0.222 | 2821 |
| 01070 | training | 3.227 | 0.221 | ---------- |
| -------- | validation | 3.258 | 0.215 | 2847 |
| 01080 | training | 3.221 | 0.220 | ---------- |
| -------- | validation | 3.239 | 0.217 | 2873 |
| 01090 | training | 3.227 | 0.220 | ---------- |
| -------- | validation | 3.200 | 0.220 | 2899 |
| 01100 | training | 3.224 | 0.220 | ---------- |
| -------- | validation | 3.204 | 0.220 | 2925 |
| 01110 | training | 3.234 | 0.219 | ---------- |
| -------- | validation | 3.225 | 0.222 | 2951 |
| 01120 | training | 3.227 | 0.220 | ---------- |
| -------- | validation | 3.260 | 0.206 | 2979 |
| 01130 | training | 3.221 | 0.221 | ---------- |
| -------- | validation | 3.221 | 0.214 | 3007 |
| 01140 | training | 3.222 | 0.221 | ---------- |
| -------- | validation | 3.221 | 0.225 | 3034 |
| 01150 | training | 3.224 | 0.220 | ---------- |
| -------- | validation | 3.202 | 0.225 | 3062 |
| 01160 | training | 3.216 | 0.222 | ---------- |
| -------- | validation | 3.233 | 0.211 | 3090 |
| 01170 | training | 3.213 | 0.221 | ---------- |
| -------- | validation | 3.284 | 0.201 | 3116 |
| 01180 | training | 3.206 | 0.222 | ---------- |
| -------- | validation | 3.175 | 0.224 | 3146 |
| 01190 | training | 3.204 | 0.222 | ---------- |
| -------- | validation | 3.184 | 0.227 | 3173 |
| 01200 | training | 3.203 | 0.222 | ---------- |
| -------- | validation | 3.209 | 0.227 | 3201 |
| 01210 | training | 3.205 | 0.223 | ---------- |
| -------- | validation | 3.211 | 0.211 | 3230 |
| 01220 | training | 3.215 | 0.221 | ---------- |
| -------- | validation | 3.162 | 0.237 | 3258 |
| 01230 | training | 3.200 | 0.223 | ---------- |
| -------- | validation | 3.257 | 0.213 | 3284 |
| 01240 | training | 3.192 | 0.223 | ---------- |
| -------- | validation | 3.201 | 0.223 | 3311 |
| 01250 | training | 3.200 | 0.222 | ---------- |
| -------- | validation | 3.239 | 0.216 | 3338 |
| 01260 | training | 3.189 | 0.223 | ---------- |
| -------- | validation | 3.234 | 0.223 | 3364 |
| 01270 | training | 3.197 | 0.222 | ---------- |
| -------- | validation | 3.232 | 0.218 | 3392 |
| 01280 | training | 3.190 | 0.224 | ---------- |
| -------- | validation | 3.168 | 0.219 | 3419 |
| 01290 | training | 3.192 | 0.223 | ---------- |
| -------- | validation | 3.192 | 0.229 | 3445 |
| 01300 | training | 3.193 | 0.222 | ---------- |
| -------- | validation | 3.173 | 0.224 | 3473 |
| 01310 | training | 3.181 | 0.224 | ---------- |
| -------- | validation | 3.207 | 0.220 | 3500 |
| 01320 | training | 3.188 | 0.223 | ---------- |
| -------- | validation | 3.226 | 0.221 | 3527 |
| 01330 | training | 3.181 | 0.224 | ---------- |
| -------- | validation | 3.215 | 0.218 | 3552 |
| 01340 | training | 3.182 | 0.224 | ---------- |
| -------- | validation | 3.147 | 0.226 | 3579 |
| 01350 | training | 3.182 | 0.223 | ---------- |
| -------- | validation | 3.157 | 0.222 | 3606 |
| 01360 | training | 3.173 | 0.224 | ---------- |
| -------- | validation | 3.168 | 0.231 | 3633 |
| 01370 | training | 3.175 | 0.226 | ---------- |
| -------- | validation | 3.154 | 0.237 | 3659 |
| 01380 | training | 3.167 | 0.227 | ---------- |
| -------- | validation | 3.163 | 0.210 | 3687 |
